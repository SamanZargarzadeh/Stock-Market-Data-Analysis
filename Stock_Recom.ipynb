{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFan7kskFLEx3czXeMN2at",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamanZargarzadeh/Stock-Market-Data-Analysis/blob/main/Stock_Recom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So3BUWtWL3m7",
        "outputId": "54cd9076-4ca6-4034-d636-c457a77a14f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.10.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ta) (1.16.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.10.2-py3-none-any.whl size=29088 sha256=9e2d21fa4203d644efd9fcef57a41660f729c0e29609ca02c6523a5a9cde4a3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/51/06/380dc516ea78621870b93ff65527c251afdfdc5fa9d7f4d248\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.10.2\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install ta\n",
        "import ta\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get historical stock data from Yahoo Finance\n",
        "def get_stock_data(ticker, start_date, end_date):\n",
        "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    return stock_data"
      ],
      "metadata": {
        "id": "0ttpc6JpOXNM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to analyze stock data and create technical indicators\n",
        "def analyze_stock(stock_data):\n",
        "    # Calculate technical indicators using the 'ta' library\n",
        "    # Use a window size for ATR that is smaller or equal to the number of data points available\n",
        "    window_size = min(10, len(stock_data))  # Use a window size of 10 or less\n",
        "\n",
        "    stock_data = ta.add_all_ta_features(\n",
        "        stock_data, open='Open', high='High', low='Low', close='Close', volume='Volume', fillna=True\n",
        "    )\n",
        "\n",
        "    # Update the ATR calculation to use the correct window size\n",
        "    stock_data[f'volatility_atr_{window_size}'] = AverageTrueRange(\n",
        "        close=stock_data['Close'], high=stock_data['High'], low=stock_data['Low'], window=window_size, fillna=True\n",
        "    ).average_true_range()\n",
        "\n",
        "    return stock_data\n"
      ],
      "metadata": {
        "id": "Ys2jWpoYOZcC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train a Random Forest model for classification\n",
        "def train_random_forest_model(stock_data):\n",
        "    X = stock_data.drop(columns=['target', 'Date', 'Adj Close'])\n",
        "    y = stock_data['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    rf_model = RandomForestClassifier(random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Random Forest Model Accuracy:\", accuracy)\n",
        "\n",
        "    return rf_model"
      ],
      "metadata": {
        "id": "MIXsTJGuOevE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train an LSTM model for stock price prediction\n",
        "def train_lstm_model(stock_data):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(stock_data[['Close']])\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(60, len(scaled_data)):\n",
        "        X.append(scaled_data[i-60:i, 0])\n",
        "        y.append(scaled_data[i, 0])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(X, y, batch_size=1, epochs=5)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "TzbXApi7OjDg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train an SVM model for classification\n",
        "def train_svm_model(stock_data):\n",
        "    X = stock_data.drop(columns=['target', 'Date', 'Adj Close'])\n",
        "    y = stock_data['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    svm_model = SVC(kernel='linear', random_state=42)\n",
        "    svm_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = svm_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"SVM Model Accuracy:\", accuracy)\n",
        "\n",
        "    return svm_model"
      ],
      "metadata": {
        "id": "sIKc_lEJPC3a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build a Deep Q-Network (DQN) model\n",
        "def build_dqn_model(input_shape, output_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(output_shape, activation='linear'))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Function to train a Deep Q-Network (DQN) model using Deep Q-Learning\n",
        "def train_dqn_model(stock_data, dqn_model, num_episodes=100, gamma=0.95, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(stock_data[['Close']])\n",
        "\n",
        "\n",
        "    memory = []  # Memory buffer for experience replay\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = scaled_data[0]  # Initial state\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            if np.random.rand() <= epsilon:\n",
        "                action = np.random.choice([0, 1, 2])  # Random action (buy, sell, hold)\n",
        "            else:\n",
        "                q_values = dqn_model.predict(np.expand_dims(state, axis=0))\n",
        "                action = np.argmax(q_values[0])\n",
        "\n",
        "            next_state = scaled_data[action + 1]\n",
        "\n",
        "            # Calculate reward based on the profit/loss from the action\n",
        "            reward = next_state[0] - state[0]\n",
        "\n",
        "            memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "            if len(memory) > 32:\n",
        "                # Perform experience replay to train the DQN\n",
        "                minibatch = np.random.choice(len(memory), size=32, replace=False)\n",
        "                for idx in minibatch:\n",
        "                    state_mem, action_mem, reward_mem, next_state_mem, done_mem = memory[idx]\n",
        "                    target = reward_mem\n",
        "\n",
        "                    if not done_mem:\n",
        "                        target = reward_mem + gamma * np.max(dqn_model.predict(np.expand_dims(next_state_mem, axis=0)))\n",
        "\n",
        "                    target_values = dqn_model.predict(np.expand_dims(state_mem, axis=0))\n",
        "                    target_values[0][action_mem] = target\n",
        "\n",
        "                    dqn_model.fit(np.expand_dims(state_mem, axis=0), target_values, epochs=1, verbose=0)\n",
        "\n",
        "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
        "        print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "\n",
        "    return dqn_model"
      ],
      "metadata": {
        "id": "NlbcgHHOPH2O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_risk_management(stock_data, model):\n",
        "    # Calculate stop-loss and take-profit levels based on ATR\n",
        "    stop_loss_pct = 0.02  # 2% stop-loss\n",
        "    take_profit_pct = 0.05  # 5% take-profit\n",
        "\n",
        "    stock_data['Stop_Loss'] = stock_data['Close'] - stock_data['ATR'] * stop_loss_pct\n",
        "    stock_data['Take_Profit'] = stock_data['Close'] + stock_data['ATR'] * take_profit_pct\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    X = stock_data[['SMA_50', 'SMA_200', 'RSI', 'MACD', 'Ichimoku_Span_A', 'Ichimoku_Span_B', 'ATR', 'CCI']]\n",
        "    stock_data['Predicted_Signal'] = model.predict(X)\n",
        "\n",
        "    # Apply risk management based on predicted signals\n",
        "    stock_data['Signal'] = 0\n",
        "    stock_data.loc[stock_data['Predicted_Signal'] == 1, 'Signal'] = 1\n",
        "    stock_data.loc[stock_data['Predicted_Signal'] == 0, 'Signal'] = -1\n",
        "\n",
        "    # Apply stop-loss and take-profit levels\n",
        "    stock_data['Trade_Type'] = stock_data['Signal'].diff()\n",
        "    stock_data.loc[stock_data['Trade_Type'] == -2, 'Signal'] = 0\n",
        "    stock_data['Signal'] = stock_data['Signal'].ffill()\n",
        "\n",
        "    return stock_data\n"
      ],
      "metadata": {
        "id": "pgege1DzPNXw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict action using the DQN model\n",
        "def dqn_predict_action(state, dqn_model):\n",
        "    q_values = dqn_model.predict(np.expand_dims(state, axis=0))\n",
        "    return np.argmax(q_values[0])"
      ],
      "metadata": {
        "id": "fvzLZwinPO_q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the latest data for the specified ticker up to the end_date\n",
        "def get_latest_data(ticker_symbol, end_date):\n",
        "    start_date = pd.to_datetime(end_date) - pd.Timedelta(days=7)  # Data for the past week\n",
        "    stock_data = get_stock_data(ticker_symbol, start_date=start_date, end_date=end_date)\n",
        "    return stock_data"
      ],
      "metadata": {
        "id": "DdTBOpqrPSDN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the weekly recommendation for the specified ticker\n",
        "def get_recommendation(ticker_symbol, end_date):\n",
        "    latest_data = get_latest_data(ticker_symbol, end_date)\n",
        "\n",
        "    # Perform analysis and train models on historical data up to the current week\n",
        "    analyzed_stock_data = analyze_stock(latest_data)\n",
        "    random_forest_model = train_random_forest_model(analyzed_stock_data)\n",
        "    lstm_model = train_lstm_model(analyzed_stock_data)\n",
        "    svm_model = train_svm_model(analyzed_stock_data)\n",
        "    input_shape = (1,)  # Number of features in the state representation\n",
        "    output_shape = 3  # Number of actions (buy, sell, hold)\n",
        "    dqn_model = build_dqn_model(input_shape, output_shape)\n",
        "    dqn_model = train_dqn_model(analyzed_stock_data, dqn_model)\n",
        "\n",
        "    # Apply risk management based on LSTM predictions\n",
        "    analyzed_stock_data = apply_risk_management(analyzed_stock_data, lstm_model)\n",
        "\n",
        "    # Predict action using DQN model for the next week\n",
        "    last_state = np.array([analyzed_stock_data['Close'].iloc[-1]])\n",
        "    action = dqn_predict_action(last_state, dqn_model)\n",
        "\n",
        "    # Convert action to human-readable recommendation\n",
        "    if action == 0:  # Buy\n",
        "        recommendation = \"Buy\"\n",
        "    elif action == 1:  # Sell\n",
        "        recommendation = \"Sell\"\n",
        "    else:  # Hold\n",
        "        recommendation = \"Hold\"\n",
        "\n",
        "    return recommendation"
      ],
      "metadata": {
        "id": "ZQokHhdhPaMs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ticker_symbol = 'AAPL'\n",
        "end_date = '2023-07-21'\n",
        "\n",
        "recommendation = get_recommendation(ticker_symbol, end_date)\n",
        "print(f\"Recommendation for {ticker_symbol} for the next week: {recommendation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bAV_zS9tMVFJ",
        "outputId": "06683bdb-c441-4a91-c2ca-b36d42107ea8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8a2c48422a09>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2023-07-21'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrecommendation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker_symbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Recommendation for {ticker_symbol} for the next week: {recommendation}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-435d39c2ffb0>\u001b[0m in \u001b[0;36mget_recommendation\u001b[0;34m(ticker_symbol, end_date)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Perform analysis and train models on historical data up to the current week\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0manalyzed_stock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_stock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mrandom_forest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_random_forest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzed_stock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzed_stock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-0cdcfbfa8bcc>\u001b[0m in \u001b[0;36manalyze_stock\u001b[0;34m(stock_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use a window size of 10 or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     stock_data = ta.add_all_ta_features(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mstock_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ta/wrapper.py\u001b[0m in \u001b[0;36madd_all_ta_features\u001b[0;34m(df, open, high, low, close, volume, fillna, colprefix, vectorized)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[0;32m--> 576\u001b[0;31m     df = add_volatility_ta(\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ta/wrapper.py\u001b[0m in \u001b[0;36madd_volatility_ta\u001b[0;34m(df, high, low, close, fillna, colprefix, vectorized)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# Average True Range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         df[f\"{colprefix}volatility_atr\"] = AverageTrueRange(\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         ).average_true_range()\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ta/volatility.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, high, low, close, window, fillna)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fillna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ta/volatility.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtrue_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_true_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0matr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0matr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             atr[i] = (atr[i - 1] * (self._window - 1) + true_range.iloc[i]) / float(\n",
            "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 5"
          ]
        }
      ]
    }
  ]
}